# LLM_SillyTry
Introduction
LLM_SillyTry is a sample project that demonstrates the use of Large Language Models (LLMs) for question answering and text summarization. It utilizes the powerful Transformers library from Hugging Face to load and fine-tune a pre-trained LLM model for these tasks.

**Features**
Question Answering: Given a passage of text and a question, the model can provide an answer based on the information in the text.

Text Summarization: The model can generate a concise summary of a given text, capturing the key points and ideas.

Model Saving and Loading: The trained model can be saved to disk and loaded later for further use or fine-tuning.

Object-Oriented Design: The code is structured in an object-oriented manner, with the 
LLMQAModel
 class encapsulating the model, tokenizer, and related functionality.

**Requirements**
Python 3.7 or higher

Transformers library (version 4.x or higher)

PyTorch (version 1.x or higher)

Usage
Clone the repository:
